{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8fe4af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import pickle\n",
    "import json\n",
    "from torchvision.datasets import CIFAR10, CIFAR100, SVHN, ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "from collections import Counter\n",
    "from helpers import *\n",
    "from explore import *\n",
    "\n",
    "pd.set_option('display.max_rows', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "21da7a96",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class CIFAR10Instance(CIFAR10):\n",
    "    def __getitem__(self, index):\n",
    "        sample = self.data[index]\n",
    "        sample = Image.fromarray(sample)\n",
    "        if self.transform is not None:\n",
    "            sample = self.transform(sample)           \n",
    "        return sample, index\n",
    "\n",
    "\n",
    "class CIFAR100Instance(CIFAR100):\n",
    "    def __getitem__(self, index):\n",
    "        sample = self.data[index]\n",
    "        sample = Image.fromarray(sample)\n",
    "        if self.transform is not None:\n",
    "            sample = self.transform(sample)           \n",
    "        return sample, index\n",
    "    \n",
    "\n",
    "class SVHNInstance(SVHN):\n",
    "    def __getitem__(self, index):\n",
    "        sample = self.data[index]\n",
    "        sample = Image.fromarray(sample.transpose(1,2,0))\n",
    "        if self.transform is not None:\n",
    "            sample = self.transform(sample)           \n",
    "        return sample, index\n",
    "    \n",
    "    \n",
    "class LSUNResize(ImageFolder):\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        sample = self.samples[index][0]\n",
    "        sample = Image.open(sample)\n",
    "        if self.transform is not None:\n",
    "            sample = self.transform(sample)           \n",
    "        return sample, index\n",
    "    \n",
    "    \n",
    "class Rot90:\n",
    "    \"\"\"\"Rotate Image if height > width\"\"\"\n",
    "    def __call__(self, y):\n",
    "        return y.transpose(Image.ROTATE_90) if y.size[0] < y.size[1] else y\n",
    "\n",
    "\n",
    "class ImageNet30(ImageFolder):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(ImageNet30, self).__init__(**kwargs)\n",
    "        \n",
    "        data_type = kwargs['root'].split(os.sep)[-1]\n",
    "        if data_type == \"train\":\n",
    "            self.gs_list = pd.read_pickle(\"/data/datasets/imgnet30_train_grayscale.pickle\")\n",
    "        else:\n",
    "            self.gs_list = pd.read_pickle(\"/data/datasets/imgnet30_val_grayscale.pickle\")\n",
    "        \n",
    "        self.imgs = list(filter (lambda x:x[0] not in self.gs_list, self.samples))\n",
    "        self.targets = [v for k,v in self.imgs]\n",
    "    \n",
    "\n",
    "class CUB(ImageFolder):\n",
    "    pass\n",
    "\n",
    "\n",
    "def eval_augmentation(x, y=224, z=True, r_and_z=True):\n",
    "    if z:\n",
    "        print(\"using center crop\")\n",
    "        if r_and_z:\n",
    "            print(\"using resize and center crop\")\n",
    "            aug = [\n",
    "                 transforms.Resize(256),\n",
    "                 transforms.CenterCrop(224),\n",
    "                 transforms.ToTensor(),\n",
    "                 transforms.Normalize(mean=means[x], std=stds[x])]\n",
    "        else:\n",
    "            aug = [\n",
    "                transforms.CenterCrop(y),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean=means[x], std=stds[x])]\n",
    "    else:\n",
    "        print(\"no center crop\")\n",
    "        aug = [\n",
    "            transforms.Resize(y),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=means[x], std=stds[x])]\n",
    "\n",
    "    if x == \"Imagenet30\":\n",
    "        print(\"imagenet30 mode\")\n",
    "        aug = [Rot90()] + aug\n",
    "    \n",
    "    aug = transforms.Compose(aug)\n",
    "    return aug \n",
    "\n",
    "\n",
    "def get_feats(data_set, id_dataset, model, gpu, img_size):\n",
    "    if model.training:\n",
    "        raise ValueError(\"Model not in eval mode\")\n",
    "    else:\n",
    "        print(\"model in eval mode\")\n",
    "        \n",
    "    train_targets = None\n",
    "    test_targets = None\n",
    "        \n",
    "    if data_set == \"CIFAR10\":\n",
    "        selected_data = CIFAR10Instance \n",
    "        root = \"/data/datasets/CIFAR10\"\n",
    "        training_data = selected_data(\n",
    "            root=root,\n",
    "            train=True,\n",
    "            download=False,\n",
    "            transform=eval_augmentation(id_dataset, img_size)\n",
    "            )\n",
    "\n",
    "        test_data = selected_data(\n",
    "            root=root,\n",
    "            train=False,\n",
    "            download=False,\n",
    "            transform=eval_augmentation(id_dataset, img_size)\n",
    "        )\n",
    "        \n",
    "        train_targets = np.array(training_data.targets)\n",
    "        test_targets = np.array(test_data.targets)\n",
    "        \n",
    "    elif data_set == \"CIFAR100\":\n",
    "        selected_data = CIFAR100Instance\n",
    "        root = \"/data/datasets/CIFAR100\"\n",
    "        training_data = selected_data(\n",
    "            root=root,\n",
    "            train=True,\n",
    "            download=False,\n",
    "            transform=eval_augmentation(id_dataset, img_size)\n",
    "            )\n",
    "\n",
    "        test_data = selected_data(\n",
    "            root=root,\n",
    "            train=False,\n",
    "            download=False,\n",
    "            transform=eval_augmentation(id_dataset, img_size)\n",
    "        )\n",
    "\n",
    "    elif data_set == \"SVHN\":\n",
    "        selected_data = SVHNInstance\n",
    "        root = \"/data/datasets/svhn-data\"\n",
    "        \n",
    "        training_data = selected_data(\n",
    "            root=root,\n",
    "            split=\"train\",\n",
    "            download=False,\n",
    "            transform=eval_augmentation(id_dataset, img_size)\n",
    "            )\n",
    "\n",
    "        test_data = selected_data(\n",
    "            root=root,\n",
    "            split='test',\n",
    "            download=False,\n",
    "            transform=eval_augmentation(id_dataset, img_size)\n",
    "        )\n",
    "        \n",
    "    elif data_set == \"LSUNResize\":\n",
    "        root = \"/data/datasets/LSUN_datasets/LSUN_resize\"\n",
    "        selected_data = LSUNResize\n",
    "        \n",
    "        training_data = selected_data(\n",
    "            root=root,\n",
    "            transform=eval_augmentation(id_dataset, img_size)\n",
    "            )\n",
    "\n",
    "        test_data = selected_data(\n",
    "            root=root,\n",
    "            transform=eval_augmentation(id_dataset, img_size)\n",
    "        )\n",
    "        \n",
    "    elif data_set == \"Imagenet30\":\n",
    "        datadir = \"/data/datasets\"\n",
    "        training_data = ImageNet30(root=os.path.join(datadir, 'ImageNet30', 'train'),\n",
    "                         transform=eval_augmentation(\"Imagenet30\", img_size, True, False))\n",
    "        \n",
    "        \n",
    "        test_data = ImageNet30(root=os.path.join(datadir, 'ImageNet30', 'val'),\n",
    "                         transform=eval_augmentation(\"Imagenet30\", img_size, True, False))\n",
    "        selected_data = training_data\n",
    "        \n",
    "    elif data_set == \"CUB\":\n",
    "        training_data = None\n",
    "        test_data = CUB(root=\"/data/datasets/cub200/CUB_200_2011/images\", \n",
    "                        transform=eval_augmentation(\"Imagenet30\", img_size, True, False))\n",
    "        selected_data = test_data\n",
    "    \n",
    "    if data_set in [\"Imagenet30\", \"CUB\"]:\n",
    "        batch_size = 128 \n",
    "    else:\n",
    "        batch_size = 256 * 4\n",
    "    \n",
    "    print(f\"selected data: {str(selected_data)}\")\n",
    "    \n",
    "    print(f\"dataset : {data_set}\")\n",
    "    if training_data:\n",
    "        train_dataloader = DataLoader(training_data, batch_size, shuffle=False)\n",
    "    test_dataloader = DataLoader(test_data, batch_size, shuffle=False)\n",
    "    train_feats = []\n",
    "    test_feats = []\n",
    "    \n",
    "    if training_data:\n",
    "        for x,y in tqdm(train_dataloader):\n",
    "            with torch.no_grad():\n",
    "                train_feats.append(model(x.to(gpu)))\n",
    "            \n",
    "    for x,y in tqdm(test_dataloader):\n",
    "        with torch.no_grad():\n",
    "            test_feats.append(model(x.to(gpu)))\n",
    "    if training_data:\n",
    "        train_feats = [i.detach().cpu().numpy() for i in train_feats]\n",
    "        train_feats = np.vstack(train_feats)\n",
    "    test_feats = [i.detach().cpu().numpy() for i in test_feats]\n",
    "    \n",
    "    print(f\"data augmentation: {str(eval_augmentation(id_dataset, img_size))}\")\n",
    "            \n",
    "    return train_feats, np.vstack(test_feats), train_targets, test_targets\n",
    "\n",
    "\n",
    "def run_clustering(data, num_cluster):\n",
    "    clus_result = run_kmeans(data, num_cluster)\n",
    "    im2cluster = np.array(clus_result['im2cluster']).flatten()\n",
    "    prototypes = np.array(clus_result['centroids'][0])\n",
    "    density = np.array(clus_result['density']).flatten()\n",
    "    return im2cluster, prototypes, density\n",
    "\n",
    "\n",
    "def softmax_t(logits, temp=1):\n",
    "    logits = logits/temp\n",
    "    _max = np.expand_dims(np.max(logits, axis=-1), axis=-1)\n",
    "    probs = np.exp(logits - _max)\n",
    "    _sum = np.expand_dims(np.sum(probs, axis=-1), axis=-1)\n",
    "    return probs/_sum\n",
    "\n",
    "\n",
    "def cluster_purity(kmeans_targets, in_targets):\n",
    "    k_classes = np.unique(kmeans_targets).astype(int)\n",
    "    k_class_idx = [np.nonzero(np.equal(cls_, kmeans_targets)) for cls_ in k_classes]\n",
    "    in_classes_in_k_clstr = [in_targets[idx] for idx in k_class_idx]\n",
    "    purity_list = []\n",
    "\n",
    "    for cluster_k in in_classes_in_k_clstr:\n",
    "        unique, counts = np.unique(cluster_k, return_counts=True)\n",
    "        purity_list.append(np.round(np.asarray(counts).max()/len(cluster_k), 5))\n",
    "\n",
    "    return purity_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9482832",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "99b2e6b0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded contrastive model @ ckpt: /data/temiloluwa.adeoti/fourth_experiments/CIFAR100_clus_1024_neg_768/exp_1/checkpoints/checkpoint_0199.pth.tar\n",
      "Outputing contrastive model from Avgpool Layer\n"
     ]
    }
   ],
   "source": [
    "model_path = \"/data/temiloluwa.adeoti/fourth_experiments/CIFAR100_clus_1024_neg_768/exp_1/checkpoints\"\n",
    "ckpt = 199\n",
    "encoder_type = \"key\"\n",
    "arch = \"resnet50\"\n",
    "num_classes = 128\n",
    "output_layer = \"avg_pool\"\n",
    "img_size = 224\n",
    "gpu = 2\n",
    "cal_feats = True\n",
    "if cal_feats:\n",
    "    model = load_model(model_path, ckpt, arch, num_classes, output_layer, encoder_type)\n",
    "    model.cuda(gpu)\n",
    "    _ = model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16efd95c",
   "metadata": {},
   "source": [
    "## Load IID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6fcdbcaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CIFAR10_key_avg_pool'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load id\n",
    "iid = \"CIFAR10\"\n",
    "save_feats = True\n",
    "prefix = f\"{iid}_{encoder_type}_{output_layer}\"\n",
    "prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "24d02676",
   "metadata": {},
   "outputs": [],
   "source": [
    "#_dat = CIFAR100(\"/data/datasets/CIFAR100\", train=False).targets\n",
    "#save_features(\"../cache\", f\"{prefix}_id_test_targ.npy\", id_test_targ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "29da7d4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model in eval mode\n",
      "using center crop\n",
      "using resize and center crop\n",
      "using center crop\n",
      "using resize and center crop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selected data: <class '__main__.CIFAR10Instance'>\n",
      "dataset : CIFAR10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:54<00:00,  1.11s/it]\n",
      "100%|██████████| 10/10 [00:11<00:00,  1.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using center crop\n",
      "using resize and center crop\n",
      "data augmentation: Compose(\n",
      "    Resize(size=256, interpolation=bilinear)\n",
      "    CenterCrop(size=(224, 224))\n",
      "    ToTensor()\n",
      "    Normalize(mean=[0.491, 0.482, 0.447], std=[0.247, 0.243, 0.262])\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "if cal_feats:\n",
    "    id_train, id_test, id_train_targ, id_test_targ = get_feats(iid, iid, model, gpu, img_size)\n",
    "\n",
    "if save_feats:\n",
    "    save_features(\"../cache\", f\"{prefix}_id_train.npy\", id_train)\n",
    "    save_features(\"../cache\", f\"{prefix}_id_test.npy\", id_test)\n",
    "    save_features(\"../cache\", f\"{prefix}_id_train_targ.npy\", id_train_targ)\n",
    "    save_features(\"../cache\", f\"{prefix}_id_test_targ.npy\", id_test_targ)\n",
    "else:\n",
    "    id_train = load_features(\"../cache\", f\"{prefix}_id_train.npy\")\n",
    "    id_test = load_features(\"../cache\", f\"{prefix}_id_test.npy\")\n",
    "    id_train_targ = load_features(\"../cache\", f\"{prefix}_id_train_targ.npy\")\n",
    "    id_test_targ = load_features(\"../cache\", f\"{prefix}_id_test_targ.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c778509f",
   "metadata": {},
   "source": [
    "## Load OOD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3cf62ac7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model in eval mode\n",
      "using center crop\n",
      "using resize and center crop\n",
      "using center crop\n",
      "using resize and center crop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selected data: <class '__main__.CIFAR100Instance'>\n",
      "dataset : CIFAR100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:54<00:00,  1.11s/it]\n",
      "100%|██████████| 10/10 [00:11<00:00,  1.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using center crop\n",
      "using resize and center crop\n",
      "data augmentation: Compose(\n",
      "    Resize(size=256, interpolation=bilinear)\n",
      "    CenterCrop(size=(224, 224))\n",
      "    ToTensor()\n",
      "    Normalize(mean=[0.491, 0.482, 0.447], std=[0.247, 0.243, 0.262])\n",
      ")\n",
      "model in eval mode\n",
      "using center crop\n",
      "using resize and center crop\n",
      "using center crop\n",
      "using resize and center crop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/72 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selected data: <class '__main__.SVHNInstance'>\n",
      "dataset : SVHN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 72/72 [01:19<00:00,  1.11s/it]\n",
      "100%|██████████| 26/26 [00:28<00:00,  1.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using center crop\n",
      "using resize and center crop\n",
      "data augmentation: Compose(\n",
      "    Resize(size=256, interpolation=bilinear)\n",
      "    CenterCrop(size=(224, 224))\n",
      "    ToTensor()\n",
      "    Normalize(mean=[0.491, 0.482, 0.447], std=[0.247, 0.243, 0.262])\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model in eval mode\n",
      "using center crop\n",
      "using resize and center crop\n",
      "using center crop\n",
      "using resize and center crop\n",
      "selected data: <class '__main__.LSUNResize'>\n",
      "dataset : LSUNResize\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:12<00:00,  1.23s/it]\n",
      "100%|██████████| 10/10 [00:12<00:00,  1.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using center crop\n",
      "using resize and center crop\n",
      "data augmentation: Compose(\n",
      "    Resize(size=256, interpolation=bilinear)\n",
      "    CenterCrop(size=(224, 224))\n",
      "    ToTensor()\n",
      "    Normalize(mean=[0.491, 0.482, 0.447], std=[0.247, 0.243, 0.262])\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# load ood\n",
    "oods = [\"CIFAR100\", \"SVHN\",  \"LSUNResize\"]\n",
    "for ood in oods:\n",
    "    save_feats = True\n",
    "    prefix = f\"{ood}_{encoder_type}_{output_layer}\"\n",
    "    prefix\n",
    "\n",
    "    if cal_feats:\n",
    "        ood_train, ood_test, _, _ = get_feats(ood, iid, model, gpu, img_size)\n",
    "\n",
    "    if save_feats:\n",
    "        save_features(\"../cache\", f\"{prefix}_ood_train.npy\", ood_train)\n",
    "        save_features(\"../cache\", f\"{prefix}_ood_test.npy\", ood_test)\n",
    "    else:\n",
    "        ood_train = load_features(\"../cache\", f\"{prefix}_ood_train.npy\")\n",
    "        ood_test = load_features(\"../cache\",  f\"{prefix}_ood_test.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dca9315c",
   "metadata": {},
   "source": [
    "## Train Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "737323f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_linear_model(id_train, id_train_targets, id_test,  id_test_targets, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "201e7c01",
   "metadata": {},
   "source": [
    "## Get Prototypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4bf3fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_prototypes = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62687d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if get_prototypes:\n",
    "    num_cluster = 768\n",
    "    id_im2cluster, id_prototypes, id_density = run_clustering(norm_feats(id_train), num_cluster)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa4ea42c",
   "metadata": {},
   "source": [
    "## Perform OOD detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49256159",
   "metadata": {},
   "outputs": [],
   "source": [
    "oe = OodEvaluator(norm_feats(id_train), norm_feats(id_test), id_train_targ, id_test_targ,\n",
    "                num_clusters = 768,\n",
    "                pca_com = 10,\n",
    "                cluster_method = \"kmeans\",\n",
    "                means = None,\n",
    "                im2cluster = None,\n",
    "                clip = 0.5,\n",
    "                clip_metric = \"cosine\")\n",
    "\n",
    "oe(norm_feats(ood_test), \"cosine\")\n",
    "oe.get_scores()\n",
    "res_df = oe.get_auroc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8809237",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prototypical-env",
   "language": "python",
   "name": "prototypical-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
